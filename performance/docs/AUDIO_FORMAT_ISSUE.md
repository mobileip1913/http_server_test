# 音频格式问题分析和解决方案

## 问题现象

从测试日志观察到：
1. ✅ 服务器正常响应（收到 STT、TTS 消息）
2. ❌ STT 识别文本为空：`Recognized text: `
3. ❌ 服务器返回"我没听清楚"的回复
4. ❌ 音频数据只有 676 字节（即使生成了 3000ms 的音频）

## 根本原因

### 1. 音频格式问题

**项目代码期望的格式**：
- 裸 Opus 数据包（Raw Opus Packets）
- 每个包最大 1000 字节
- 每帧 60ms
- 从 `main/application.cc` 看，读取的是 30ms 的 PCM，编码为 60ms 的 Opus 帧

**当前测试代码生成的格式**：
- ffmpeg 默认生成 **Ogg Opus 容器格式**（包含 Ogg 头）
- 文件以 `OggS` 开头，不是裸 Opus 数据包
- 服务器无法直接解析 Ogg 容器格式

### 2. 音频内容问题

- 当前生成的是**静音音频**（`anullsrc`）
- 即使服务器能解析格式，静音也无法被识别为语音
- Opus 的 DTX（不连续传输）会将静音压缩到极小（676 字节）

### 3. 音频分割问题

- 当前将整个 Opus 文件作为单个帧发送
- 实际应该分割为多个 60ms 的 Opus 数据包
- 每个包独立发送

## 解决方案

### 方案1：使用真实 TTS 服务（推荐）

使用真实的 TTS 服务生成语音，而不是静音：

```python
# 使用 Azure TTS、Google TTS 或其他服务
# 生成真实的语音数据，然后编码为 Opus
```

### 方案2：使用预录制的音频文件

提供预录制的 WAV/MP3 文件：

```bash
export AUDIO_FILE_PATH="/path/to/test_audio.wav"
```

然后在 `audio_encoder.py` 中正确转换为裸 Opus 数据包。

### 方案3：修复当前生成逻辑（临时方案）

1. **生成真实语音**（使用 TTS 或预录制）
2. **转换为裸 Opus 数据包**（不是 Ogg 容器）
3. **分割为 60ms 帧**

## 当前代码的限制

1. `audio_encoder.py` 中的 `_generate_test_opus_frames()` 生成的是静音
2. 没有实现 Opus 数据包分割（返回整个文件作为一帧）
3. ffmpeg 生成的是 Ogg 容器格式，不是裸 Opus 数据包

## 临时解决方案

如果只是测试连接和响应流程，可以：
1. 使用文本模式（`SEND_AUDIO_DATA=false`）- 只发送 `start_listen` 消息
2. 服务器会返回响应（虽然可能还是"我没听清楚"）

但这样无法测试真实的音频识别流程。

## 建议

**短期**：修复 `connect_status` 判断逻辑（已完成），统计应该会正确显示

**长期**：
1. 集成真实的 TTS 服务生成测试音频
2. 实现 Opus 数据包的正确分割
3. 确保生成的是裸 Opus 格式，不是 Ogg 容器

## 验证方法

运行测试后检查：
1. CSV 中的 `connect_status` 应该是 `success`（已修复）
2. CSV 中的 `complete` 应该是 `True`（已修复）
3. 如果 STT 识别成功，应该能看到识别文本
4. 如果音频格式正确，应该能识别出内容，而不是"我没听清楚"

